{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T07:09:52.385777Z",
     "start_time": "2024-07-04T07:09:52.128475Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from src.utils import read_pickles, dl_data_pipeline\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import label_ranking_average_precision_score, ndcg_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pickle\n",
    "import tqdm\n",
    "import xgboost as xgb\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6275446f7ab6a190",
   "metadata": {},
   "source": [
    "### Part 1: Train User-User filtering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "360bf94e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (800167, 6)\n"
     ]
    }
   ],
   "source": [
    "# read data\n",
    "df_movies, df_users, df_ratings = read_pickles(\"../../data/ml-1m-after_eda/\")\n",
    "train_ratings, _ = train_test_split(df_ratings, test_size=0.2, shuffle=False)\n",
    "print(f\"Train shape: {train_ratings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "250088ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training of user-user filtering\n",
    "\n",
    "def get_close_users(train_ratings, n_neighbors=30):\n",
    "    # compute average ratings per user\n",
    "    users_avrg = train_ratings.groupby('UserID')['Rating'].mean().to_dict()\n",
    "    \n",
    "    # create rating matrix\n",
    "    rating_matrix = train_ratings.pivot_table(index='UserID', columns='MovieID', values='Rating')\n",
    "\n",
    "    # calculate similarity \n",
    "    user_similarity = cosine_similarity(rating_matrix.fillna(0))\n",
    "    user_similarity_df = pd.DataFrame(user_similarity, index=rating_matrix.index, columns=rating_matrix.index)\n",
    "\n",
    "    # find N n_neighbors for each user\n",
    "    neighbors_dict = {}\n",
    "    for i in range(user_similarity_df.shape[0]):\n",
    "        row = user_similarity_df.iloc[i]\n",
    "        user = row.index[i]\n",
    "        row = row[row.index != user]\n",
    "        neighbors = list(np.argsort(row)[::-1][:n_neighbors])\n",
    "        neighbors_dict[user] = neighbors\n",
    "    \n",
    "    return rating_matrix, users_avrg, neighbors_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7718e3df2ab57297",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T07:09:56.150273Z",
     "start_time": "2024-07-04T07:09:55.398563Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users neighbors:\n",
      "[(1, [1479, 1281, 1357, 1474, 539, 1856, 2175, 4716, 1848, 679]), (2, [3106, 93, 2812, 4599, 2301, 298, 3993, 3359, 4784, 556]), (3, [2998, 477, 3498, 1902, 4318, 2260, 2433, 309, 4058, 801]), (4, [4141, 1573, 560, 85, 3664, 2345, 3459, 1347, 1576, 4000]), (5, [1482, 4605, 223, 2916, 1405, 3536, 279, 3052, 750, 1253])]\n",
      "Users average:\n",
      "[(1, 4.188679245283019), (2, 3.7131782945736433), (3, 3.9019607843137254), (4, 4.190476190476191), (5, 3.1464646464646466)]\n",
      "Rating matrix:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>127</th>\n",
       "      <th>3382</th>\n",
       "      <th>1843</th>\n",
       "      <th>286</th>\n",
       "      <th>3530</th>\n",
       "      <th>2198</th>\n",
       "      <th>2703</th>\n",
       "      <th>2845</th>\n",
       "      <th>3607</th>\n",
       "      <th>2909</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UserID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 3706 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        1     2     3     4     5     6     7     8     9     10    ...  127   \\\n",
       "UserID                                                              ...         \n",
       "1        5.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
       "2        NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
       "3        NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
       "\n",
       "        3382  1843  286   3530  2198  2703  2845  3607  2909  \n",
       "UserID                                                        \n",
       "1        NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "2        NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "3        NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "\n",
       "[3 rows x 3706 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_matrix, users_avrg, neighbors_dict = get_close_users(train_ratings, n_neighbors=10)\n",
    "\n",
    "# identify all movie IDs that need to be added to the rating matrix, and fill them with None\n",
    "new_movie_ids = [movie_id for movie_id in df_ratings['MovieID'].unique() if movie_id not in rating_matrix.columns]\n",
    "new_columns = pd.DataFrame(None, index=rating_matrix.index, columns=new_movie_ids)\n",
    "rating_matrix = pd.concat([rating_matrix, new_columns], axis=1)\n",
    "\n",
    "print(\"Users neighbors:\")\n",
    "print(list(neighbors_dict.items())[:5])\n",
    "print(\"Users average:\")\n",
    "print(list(users_avrg.items())[:5])\n",
    "print(\"Rating matrix:\")\n",
    "rating_matrix.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163c2f67",
   "metadata": {},
   "source": [
    "### Part 2: Use User-User filtering (for choosing top % movies) + XGBoost for ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d15c8b889f15bfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare complete dataset for XGBoost\n",
    "df_all = dl_data_pipeline(df_movies, df_users, df_ratings)\n",
    "train_data, test_data = train_test_split(df_all, test_size=0.2, shuffle=False)\n",
    "\n",
    "with open('../../artifacts/bst_ndcg_model.pkl', 'rb') as file:\n",
    "    bst_pairwise = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed6f304f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1783 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1783/1783 [00:34<00:00, 51.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Average Precision (MAP): 0.7124543358900729\n",
      "Normalized Discounted Cumulative Gain (NDCG): 0.9147078190581672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "map_scores = []\n",
    "ndcg_scores = []\n",
    "\n",
    "test_user_ids = test_data['UserID'].unique()\n",
    "test_movie_ids = test_data['UserID'].unique()\n",
    "\n",
    "for user_id in tqdm.tqdm(test_user_ids):\n",
    "    user_dataset =  test_data[test_data['UserID'] == user_id]\n",
    "\n",
    "    if user_id in neighbors_dict:\n",
    "        neighbors_ids = neighbors_dict[user_id]\n",
    "        user_avrg = users_avrg[user_id]\n",
    "    else:\n",
    "        # if users is not in train: all users are neighbors\n",
    "        neighbors_ids = list(neighbors_dict.keys())\n",
    "        # if users is not in train: fillnan with dataset average\n",
    "        user_avrg = np.mean(list(users_avrg.values()))\n",
    "    \n",
    "    # FIRST STAGE\n",
    "    movie_ids = user_dataset['MovieID'].to_list()\n",
    "    first_stage_rating = rating_matrix.loc[neighbors_ids, movie_ids].mean()\n",
    "    first_stage_rating = first_stage_rating.fillna(user_avrg).values.flatten()\n",
    "\n",
    "    # INTERMIDIATE STAGE\n",
    "    # choose 50% of movies, filter inputs to second stage\n",
    "    sorted_indices = np.argsort(first_stage_rating)\n",
    "    top_indices = sorted_indices[int(len(sorted_indices) * 0.5):]\n",
    "    features = user_dataset.drop(['UserID', 'Rating'], axis=1).iloc[top_indices]\n",
    "    labels = user_dataset['Rating'].iloc[top_indices]\n",
    "\n",
    "    # SECOND STAGE\n",
    "    dtest_group = xgb.DMatrix(data=features, label=labels)\n",
    "    preds = bst_pairwise.predict(dtest_group)\n",
    "\n",
    "    # METRICS\n",
    "    binary_actual = (labels >= 4).astype(int)\n",
    "    map_score = label_ranking_average_precision_score([binary_actual], [preds.argsort()[::-1]])\n",
    "    map_scores.append(map_score)\n",
    "\n",
    "    if len(preds) > 1:\n",
    "        ndcg_score_val = ndcg_score([binary_actual], [preds], k=len(labels))\n",
    "        ndcg_scores.append(ndcg_score_val)\n",
    "\n",
    "average_map = np.mean(map_scores)\n",
    "average_ndcg = np.mean(ndcg_scores)\n",
    "\n",
    "print(f\"Mean Average Precision (MAP): {average_map}\")\n",
    "print(f\"Normalized Discounted Cumulative Gain (NDCG): {average_ndcg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57805089",
   "metadata": {},
   "source": [
    "### Creating a Two-Stage Class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "009ee7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoStagePipeline:\n",
    "    def __init__(self):\n",
    "        self.neighbors_dict = {}\n",
    "        self.users_avrg = {}\n",
    "        self.second_stage_model = None\n",
    "        self.rating_matrix = None\n",
    "\n",
    "    def init_first_stage(self, train_ratings, n_neighbors=30):\n",
    "        self.users_avrg = train_ratings.groupby('UserID')['Rating'].mean().to_dict()\n",
    "        self.rating_matrix = train_ratings.pivot_table(index='UserID', columns='MovieID', values='Rating')\n",
    "\n",
    "        user_similarity = cosine_similarity(self.rating_matrix.fillna(0))\n",
    "        user_similarity_df = pd.DataFrame(user_similarity, index=self.rating_matrix.index, columns=self.rating_matrix.index)\n",
    "\n",
    "        # find N neighbors for each user\n",
    "        for i in range(user_similarity_df.shape[0]):\n",
    "            row = user_similarity_df.iloc[i]\n",
    "            user = row.index[i]\n",
    "            row = row[row.index != user]\n",
    "            neighbors = np.array((np.argsort(row)[::-1][:n_neighbors]))+1\n",
    "            self.neighbors_dict[user] = list(neighbors)\n",
    "\n",
    "    def update_first_stage(self, movie_ids):\n",
    "        new_movie_ids = [movie_id for movie_id in movie_ids if movie_id not in self.rating_matrix.columns]\n",
    "        new_columns = pd.DataFrame(None, index=self.rating_matrix.index, columns=new_movie_ids)\n",
    "        self.rating_matrix = pd.concat([self.rating_matrix, new_columns], axis=1)\n",
    "\n",
    "    def init_second_stage(self, model_path):\n",
    "        with open(model_path, 'rb') as file:\n",
    "            self.second_stage_model = pickle.load(file)\n",
    "\n",
    "    def one_user_rank(self, user_id, user_dataset, filter_proportion):\n",
    "        movie_ids = user_dataset['MovieID'].to_list()\n",
    "\n",
    "        # 1 use first stage\n",
    "        local_user_ids = self.neighbors_dict.get(user_id, list(self.neighbors_dict.keys()))\n",
    "        first_stage_rating = self.rating_matrix.loc[local_user_ids, movie_ids].mean()\n",
    "        first_stage_rating = first_stage_rating.fillna(np.mean(list(self.users_avrg.values()))).values.flatten()\n",
    "\n",
    "        # 2 selecting top 50%\n",
    "        sorted_indices = np.argsort(first_stage_rating)\n",
    "        top_indices = sorted_indices[int(len(sorted_indices) * filter_proportion):]\n",
    "        features = user_dataset.drop(['UserID', 'Rating'], axis=1).iloc[top_indices]\n",
    "        labels = user_dataset['Rating'].iloc[top_indices]\n",
    "        \n",
    "        # 3 use second stage\n",
    "        dtest_group = xgb.DMatrix(data=features, label=labels)\n",
    "        preds = self.second_stage_model.predict(dtest_group)\n",
    "\n",
    "        return labels, preds\n",
    "\n",
    "    def calc_metrics(self, labels, preds, binary_margin):\n",
    "        binary_actual = (labels >= binary_margin).astype(int)\n",
    "        map_score = label_ranking_average_precision_score([binary_actual], [preds.argsort()[::-1]])\n",
    "        ndcg_score_ = ndcg_score([binary_actual], [preds], k=len(labels)) if len(preds) > 1 else None\n",
    "        return map_score, ndcg_score_\n",
    "    \n",
    "    def run_evaluation(self, test_data, filter_proportion=0.5, binary_margin=4):\n",
    "        map_scores, ndcg_scores = [], []\n",
    "        for user_id in tqdm.tqdm(test_data['UserID'].unique()):\n",
    "\n",
    "            # choose one user ratings\n",
    "            user_dataset = test_data[test_data['UserID'] == user_id]\n",
    "            \n",
    "            # go through pipelune\n",
    "            labels, preds = self.one_user_rank(user_id, user_dataset, filter_proportion)\n",
    "            map_score, ndcg_score_ = self.calc_metrics(labels, preds, binary_margin)\n",
    "\n",
    "            # update scores\n",
    "            map_scores.append(map_score)\n",
    "            if ndcg_score_ != None:\n",
    "                ndcg_scores.append(ndcg_score_)\n",
    "        \n",
    "        self.average_map = np.mean(map_scores)\n",
    "        self.average_ndcg = np.mean(ndcg_scores)\n",
    "        print(f\"Mean Average Precision (MAP): {self.average_map}\")\n",
    "        print(f\"Normalized Discounted Cumulative Gain (NDCG): {self.average_ndcg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "166ec394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of rating_matrix (Users*Movies): (4795, 3706)\n",
      "Class of second stage model: <class 'xgboost.core.Booster'>\n"
     ]
    }
   ],
   "source": [
    "# prepare data\n",
    "train_ratings, _ = train_test_split(df_ratings, test_size=0.2, shuffle=False)\n",
    "train_data, test_data = train_test_split(df_all, test_size=0.2, shuffle=False)\n",
    "movie_ids = df_ratings['MovieID'].unique()\n",
    "\n",
    "# init pipeline\n",
    "pipeline = TwoStagePipeline()\n",
    "\n",
    "# configure first and second stage and update for all possible movies IDs\n",
    "pipeline.init_first_stage(train_ratings, n_neighbors=30)\n",
    "pipeline.update_first_stage(movie_ids)\n",
    "print(f\"Shape of rating_matrix (Users*Movies): {pipeline.rating_matrix.shape}\")\n",
    "\n",
    "# configure second stage\n",
    "pipeline.init_second_stage(\"../../artifacts/bst_ndcg_model.pkl\")\n",
    "print(f\"Class of second stage model: {type(pipeline.second_stage_model)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38e41956",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1783/1783 [00:37<00:00, 47.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Average Precision (MAP): 0.7397744369401572\n",
      "Normalized Discounted Cumulative Gain (NDCG): 0.919433240979977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# run evaluation (with n_neighbors=30)\n",
    "pipeline.run_evaluation(test_data, filter_proportion=0.5, binary_margin=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb9deb49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1783/1783 [00:35<00:00, 50.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Average Precision (MAP): 0.7424674780520268\n",
      "Normalized Discounted Cumulative Gain (NDCG): 0.9197015400708247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# run evaluation (with n_neighbors=50)\n",
    "pipeline.init_first_stage(train_ratings, n_neighbors=50)\n",
    "pipeline.update_first_stage(movie_ids)\n",
    "pipeline.run_evaluation(test_data, filter_proportion=0.5, binary_margin=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc564c7b",
   "metadata": {},
   "source": [
    "More n_neighbors gives better ranking results (with such manner we avoid None data), however increase models complexity."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
