{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T11:24:08.939975Z",
     "start_time": "2024-08-10T11:24:08.935542Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from src.utils import TrainTestSplitter, read_pickles, dl_data_pipeline\n",
    "from src.models import ItemItemModel, BaseModelAverage\n",
    "from src.metrics import ml_metrics, predictive_metrics, rank_metrics\n",
    "from tqdm import tqdm\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import label_ranking_average_precision_score, ndcg_score\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T11:24:12.718744Z",
     "start_time": "2024-08-10T11:24:09.724078Z"
    }
   },
   "outputs": [],
   "source": [
    "# read and prepare data\n",
    "\n",
    "df_movies, df_users, df_ratings = read_pickles(\"../../data/ml-1m-after_eda/\")\n",
    "df_all = dl_data_pipeline(df_movies, df_users, df_ratings)\n",
    "\n",
    "train_data, test_data = train_test_split(df_all.reset_index(drop=True), test_size=0.2, random_state=42)\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "test_data = test_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test to DMatrix\n",
    "\n",
    "alltrain = train_data.drop(columns=[\"UserID\", \"Rating\"])\n",
    "alltest = test_data.drop(columns=[\"UserID\", \"Rating\"])\n",
    "\n",
    "dtrain = xgb.DMatrix(data=alltrain, label=train_data['Rating'])\n",
    "dtest = xgb.DMatrix(data=alltest, label=test_data['Rating']) # we will create new DMatrix for each group (users' lists)\n",
    "\n",
    "# specify groups for training\n",
    "train_groups = train_data.groupby('UserID').size().to_numpy()\n",
    "dtrain.set_group(train_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using XGBoost for Leaning to Rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's why XGBoost is highly effective for this ranking task: dataset has sparse data, where many user-item interactions are missing –  XGBoost efficiently handles sparse data through its sparse-aware split finding algorithm, which can skip over missing values or assign them a default direction in tree splits, thereby optimizing computation and memory usage.\n",
    "\n",
    "In the context of learning to rank using models like XGBoost, pairwise and NDCG (Normalized Discounted Cumulative Gain) represent two different types of ranking strategies. Here's a breakdown of the differences between the two:\n",
    "\n",
    "### Pairwise Approach\n",
    "The pairwise approach focuses on comparing pairs of items at a time during the training process. The fundamental idea is to minimize the number of inversions in ranking — that is, cases where a lower-ranked item (according to the model) should actually be ranked higher than a higher-ranked item (again, according to the model).\n",
    "It's effective in scenarios where the goal is to maximize the accuracy of item comparisons rather than to achieve an accurate scoring of the items' ranks.\n",
    "\n",
    "### NDCG Approach\n",
    "NDCG is a listwise approach that evaluates the entire list of items at once. NDCG measures the gain of each item based on its position in the result list, giving higher importance to hits at higher ranks. This approach directly optimizes the model based on how well it ranks items in the order of their relevance, taking into account the position of items in the ranked list.\n",
    "Thus, a model optimizing for NDCG tries to place the most relevant items at the top, where their contribution to the score is maximized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training models (we will test both)\n",
    "\n",
    "param_pairwise = {\n",
    "    'objective': 'rank:pairwise',\n",
    "    'learning_rate': 0.1,\n",
    "    'gamma': 1.0,\n",
    "    'min_child_weight': 0.1,\n",
    "    'max_depth': 6,\n",
    "}\n",
    "\n",
    "bst_pairwise = xgb.train(param_pairwise, dtrain, num_boost_round=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_ndcg = {\n",
    "    'objective': 'rank:ndcg',\n",
    "    'max_depth': 6,\n",
    "    'eta': 0.1,\n",
    "    'verbosity': 1\n",
    "}\n",
    "\n",
    "bst_ndcg = xgb.train(param_ndcg, dtrain, num_boost_round=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the ranking metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T11:29:50.585006Z",
     "start_time": "2024-08-10T11:29:48.767591Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6036/6036 [00:41<00:00, 143.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pair-Wise:\n",
      "Mean Average Precision (MAP): 0.6784611491448017\n",
      "Normalized Discounted Cumulative Gain (NDCG): 0.9068129363607733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "map_scores = []\n",
    "ndcg_scores = []\n",
    "\n",
    "user_ids = test_data['UserID'].unique()\n",
    "\n",
    "for user_id in tqdm(user_ids):\n",
    "\n",
    "    # filter\n",
    "    group =  test_data[test_data['UserID'] == user_id]\n",
    "    \n",
    "    # real values\n",
    "    actual = group['Rating'].values\n",
    "\n",
    "    # prediction\n",
    "    group_features = group.drop(['UserID', 'Rating'], axis=1)\n",
    "    group_labels = group['Rating']\n",
    "    dtest_group = xgb.DMatrix(data=group_features, label=group_labels)\n",
    "    preds = bst_pairwise.predict(dtest_group)\n",
    "\n",
    "    # calc metrics\n",
    "    binary_actual = (actual >= 4).astype(int)\n",
    "    map_score = label_ranking_average_precision_score([binary_actual], [preds.argsort()[::-1]])\n",
    "    map_scores.append(map_score)\n",
    "\n",
    "    if len(preds) > 1:\n",
    "        ndcg_score_val = ndcg_score([binary_actual], [preds], k=len(actual))\n",
    "        ndcg_scores.append(ndcg_score_val)\n",
    "\n",
    "average_map = np.mean(map_scores)\n",
    "average_ndcg = np.mean(ndcg_scores) if ndcg_scores else 0.0  # handle cases where ndcg_scores might be empty\n",
    "\n",
    "print(\"Pair-Wise:\")\n",
    "print(f\"Mean Average Precision (MAP): {average_map}\")\n",
    "print(f\"Normalized Discounted Cumulative Gain (NDCG): {average_ndcg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6036/6036 [00:44<00:00, 134.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG:\n",
      "Mean Average Precision (MAP): 0.6779910469828875\n",
      "Normalized Discounted Cumulative Gain (NDCG): 0.9072433808627288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "map_scores = []\n",
    "ndcg_scores = []\n",
    "\n",
    "user_ids = test_data['UserID'].unique()\n",
    "for user_id in tqdm(user_ids):\n",
    "    # filter\n",
    "    group =  test_data[test_data['UserID'] == user_id]\n",
    "    # real values\n",
    "    actual = group['Rating'].values\n",
    "\n",
    "    # prediction\n",
    "    group_features = group.drop(['UserID', 'Rating'], axis=1)\n",
    "    group_labels = group['Rating']\n",
    "    dtest_group = xgb.DMatrix(data=group_features, label=group_labels)\n",
    "    preds = bst_ndcg.predict(dtest_group)\n",
    "\n",
    "    # calc metrics\n",
    "    binary_actual = (actual >= 4).astype(int)\n",
    "    map_score = label_ranking_average_precision_score([binary_actual], [preds.argsort()[::-1]])\n",
    "    map_scores.append(map_score)\n",
    "\n",
    "    if len(preds) > 1:\n",
    "        ndcg_score_val = ndcg_score([binary_actual], [preds], k=len(actual))\n",
    "        ndcg_scores.append(ndcg_score_val)\n",
    "\n",
    "average_map = np.mean(map_scores)\n",
    "average_ndcg = np.mean(ndcg_scores) if ndcg_scores else 0.0  # handle cases where ndcg_scores might be empty\n",
    "\n",
    "print(\"NDCG:\")\n",
    "print(f\"Mean Average Precision (MAP): {average_map}\")\n",
    "print(f\"Normalized Discounted Cumulative Gain (NDCG): {average_ndcg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ../../artifacts/bst_ndcg_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# save better model\n",
    "import pickle\n",
    "model_filename = '../../artifacts/bst_ndcg_model.pkl'\n",
    "with open(model_filename, 'wb') as file:\n",
    "    pickle.dump(bst_ndcg, file)\n",
    "print(f\"Model saved to {model_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Deep Learning Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T11:32:34.154461Z",
     "start_time": "2024-08-10T11:32:32.800917Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from  src.models import MovieLensDataset, RankingNetwork\n",
    "\n",
    "df = df_all.copy()\n",
    "user_encoder = LabelEncoder()\n",
    "movie_encoder = LabelEncoder()\n",
    "df['user_id'] = user_encoder.fit_transform(df['UserID'])\n",
    "df['movie_id'] = movie_encoder.fit_transform(df['MovieID'])\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "train_dataset = MovieLensDataset(train_df)\n",
    "train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True)\n",
    "\n",
    "model = RankingNetwork(len(user_encoder.classes_), len(movie_encoder.classes_))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "def train(model, data_loader, epochs):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for users, movies, ratings in data_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(users, movies).squeeze()\n",
    "            loss = criterion(outputs, ratings)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f'Epoch {epoch+1}, Loss: {total_loss / len(data_loader)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T11:33:26.980741Z",
     "start_time": "2024-08-10T11:32:34.155304Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.3714783945223954\n",
      "Epoch 2, Loss: 0.878379925808995\n",
      "Epoch 3, Loss: 0.8360544551433239\n",
      "Epoch 4, Loss: 0.8187176803709678\n",
      "Epoch 5, Loss: 0.8077725702878839\n",
      "Epoch 6, Loss: 0.7999195014522843\n",
      "Epoch 7, Loss: 0.7927544346163842\n",
      "Epoch 8, Loss: 0.7861292482719007\n",
      "Epoch 9, Loss: 0.7798358838449895\n",
      "Epoch 10, Loss: 0.77430417125071\n",
      "Epoch 11, Loss: 0.7681412651458003\n",
      "Epoch 12, Loss: 0.7624278237860858\n",
      "Epoch 13, Loss: 0.7563189638019447\n",
      "Epoch 14, Loss: 0.7504911535989758\n",
      "Epoch 15, Loss: 0.7443604139052212\n",
      "   MovieID  PredictedRating\n",
      "0     1620         5.297952\n",
      "1     2873         5.191571\n",
      "2     2698         5.134268\n",
      "3      744         5.133360\n",
      "4     2816         5.100731\n"
     ]
    }
   ],
   "source": [
    "train(model, train_loader, epochs=15)\n",
    "\n",
    "user_id = 0\n",
    "top_movies_df = model.predict_all_movies(user_id, num_top_movies=5)\n",
    "\n",
    "print(top_movies_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation using already defined metrics + MAP + NDCG#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T11:33:27.735488Z",
     "start_time": "2024-08-10T11:33:26.981622Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mae': 0.727, 'rmse': 0.92, 'precision': 0.842, 'recall': 0.421, 'f1': 0.562, 'roc_auc': 0.657, 'map': 0.575549093276752, 'ndcg': 0.9815455938172669}\n"
     ]
    }
   ],
   "source": [
    "test_dataset = MovieLensDataset(test_df)\n",
    "test_loader = DataLoader(test_dataset, batch_size=512, shuffle=True)\n",
    "\n",
    "test_metrics = model.evaluate(test_loader)\n",
    "print(test_metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
