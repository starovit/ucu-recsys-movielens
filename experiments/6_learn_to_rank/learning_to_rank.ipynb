{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T11:24:08.939975Z",
     "start_time": "2024-08-10T11:24:08.935542Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from src.utils import TrainTestSplitter, read_pickles, dl_data_pipeline\n",
    "from src.models import ItemItemModel, BaseModelAverage\n",
    "from src.metrics import ml_metrics, predictive_metrics, rank_metrics\n",
    "from tqdm import tqdm\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import label_ranking_average_precision_score, ndcg_score\n",
    "\n",
    "tqdm.pandas()"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T11:24:12.718744Z",
     "start_time": "2024-08-10T11:24:09.724078Z"
    }
   },
   "source": [
    "df_movies, df_users, df_ratings = read_pickles(\"../../data/ml-1m-after_eda/\")\n",
    "df_all = dl_data_pipeline(df_movies, df_users, df_ratings)\n",
    "\n",
    "train_data, test_data = train_test_split(df_all.reset_index(drop=True), test_size=0.2, random_state=42)\n",
    "\n",
    "alltrain = train_data.drop(columns=[\"UserID\", \"Rating\"])\n",
    "alltest = test_data.drop(columns=[\"UserID\", \"Rating\"])\n",
    "\n",
    "dtrain = xgb.DMatrix(data=alltrain, label=train_data['Rating'])\n",
    "dtest = xgb.DMatrix(data=alltest, label=test_data['Rating'])\n"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using XGBoost for Leaning to Rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost is considered one of the best tools for implementing learning to rank models due to several strengths it has particularly suited for ranking tasks, such as those encountered with the MovieLens dataset. Here's why XGBoost is highly effective for these tasks:\n",
    "\n",
    "MovieLens and similar datasets often feature sparse data, where many user-item interactions are missing (i.e., most users have not rated most movies). XGBoost efficiently handles sparse data through its sparse-aware split finding algorithm, which can skip over missing values or assign them a default direction in tree splits, thereby optimizing computation and memory usage.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T11:25:34.915310Z",
     "start_time": "2024-08-10T11:24:14.316891Z"
    }
   },
   "source": [
    "# Training models\n",
    "param_pairwise = {\n",
    "    'objective': 'rank:pairwise',\n",
    "    'learning_rate': 0.1,\n",
    "    'gamma': 1.0,\n",
    "    'min_child_weight': 0.1,\n",
    "    'max_depth': 6,\n",
    "    'n_estimators': 100\n",
    "}\n",
    "\n",
    "bst_pairwise = xgb.train(param_pairwise, dtrain, num_boost_round=100)\n",
    "\n",
    "param_ndcg = {\n",
    "    'objective': 'rank:ndcg',\n",
    "    'max_depth': 6,\n",
    "    'eta': 0.1,\n",
    "    'verbosity': 1\n",
    "}\n",
    "\n",
    "bst_ndcg = xgb.train(param_ndcg, dtrain, num_boost_round=100)\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuriivoievidka/UCU/Data Visualisation/venv/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [14:24:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the context of learning to rank using models like XGBoost, pairwise and NDCG (Normalized Discounted Cumulative Gain) represent two different types of ranking strategies. Both approaches aim to optimize the order of items but do so using different methodologies and objectives. Here's a breakdown of the differences between the two:\n",
    "\n",
    "### Pairwise Approach\n",
    "*Concept*: The pairwise approach focuses on comparing pairs of items at a time during the training process. The fundamental idea is to minimize the number of inversions in ranking â€” that is, cases where a lower-ranked item (according to the model) should actually be ranked higher than a higher-ranked item (again, according to the model).\n",
    "\n",
    "*Objective*: The model learns by comparing every pair of items within the same query or user session and attempts to correctly order each pair. The loss function typically penalizes the model more when it incorrectly orders a pair that is relatively close in the true order and less when the pair is far apart.\n",
    "\n",
    "*Suitability*: This approach is useful when the relative order between items is more important than the actual rank positions or the magnitude of scores. It's effective in scenarios where the goal is to maximize the accuracy of item comparisons rather than to achieve an accurate scoring of the items' ranks.\n",
    "\n",
    "### NDCG Approach\n",
    "*Concept*: NDCG is a listwise approach that evaluates the entire list of items at once. NDCG measures the gain of each item based on its position in the result list, giving higher importance to hits at higher ranks. This approach directly optimizes the model based on how well it ranks items in the order of their relevance, taking into account the position of items in the ranked list.\n",
    "\n",
    "*Objective*: The NDCG loss function is designed to maximize the gain from highly relevant items appearing at the top of the list. The gain is discounted at lower ranks, which reflects the reduced utility of items found lower in the list. Thus, a model optimizing for NDCG tries to place the most relevant items at the top, where their contribution to the score is maximized.\n",
    "\n",
    "*Suitability*: NDCG is particularly effective in situations where the quality of the top-ranked results is much more important than the overall order of all items. This makes it highly relevant for search engines and recommendation systems where the top few results are critical for user satisfaction."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T11:25:49.598944Z",
     "start_time": "2024-08-10T11:25:49.557033Z"
    }
   },
   "source": [
    "predictions_pairwise = bst_pairwise.predict(dtest)\n",
    "predictions_ndcg = bst_ndcg.predict(dtest)"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Evaluate the ranking metrics"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T11:29:50.585006Z",
     "start_time": "2024-08-10T11:29:48.767591Z"
    }
   },
   "source": [
    "grouped_test_data = test_data.groupby('UserID')\n",
    "map_scores = []\n",
    "ndcg_scores = []\n",
    "\n",
    "for user_id, group in grouped_test_data:\n",
    "    group.reset_index(drop=True, inplace=True)\n",
    "    actual = group['Rating'].values\n",
    "    \n",
    "    preds = predictions_pairwise[group.index]\n",
    "\n",
    "    binary_actual = (actual >= 4).astype(int)\n",
    "\n",
    "    map_score = label_ranking_average_precision_score([binary_actual], [preds.argsort()[::-1]])\n",
    "    map_scores.append(map_score)\n",
    "\n",
    "    if len(preds) > 1:\n",
    "        ndcg_score_val = ndcg_score([binary_actual], [preds], k=len(actual))\n",
    "        ndcg_scores.append(ndcg_score_val)\n",
    "\n",
    "average_map = np.mean(map_scores)\n",
    "average_ndcg = np.mean(ndcg_scores) if ndcg_scores else 0.0  # Handle cases where ndcg_scores might be empty\n",
    "\n",
    "print(f\"Mean Average Precision (MAP): {average_map}\")\n",
    "print(f\"Normalized Discounted Cumulative Gain (NDCG): {average_ndcg}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Average Precision (MAP): 0.6884599797250325\n",
      "Normalized Discounted Cumulative Gain (NDCG): 0.8362216845871187\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Deep Learning Approach"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T11:32:34.154461Z",
     "start_time": "2024-08-10T11:32:32.800917Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from  src.models import MovieLensDataset, RankingNetwork\n",
    "\n",
    "df = df_all.copy()\n",
    "user_encoder = LabelEncoder()\n",
    "movie_encoder = LabelEncoder()\n",
    "df['user_id'] = user_encoder.fit_transform(df['UserID'])\n",
    "df['movie_id'] = movie_encoder.fit_transform(df['MovieID'])\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "train_dataset = MovieLensDataset(train_df)\n",
    "train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True)\n",
    "\n",
    "model = RankingNetwork(len(user_encoder.classes_), len(movie_encoder.classes_))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "def train(model, data_loader, epochs):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for users, movies, ratings in data_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(users, movies).squeeze()\n",
    "            loss = criterion(outputs, ratings)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f'Epoch {epoch+1}, Loss: {total_loss / len(data_loader)}')\n"
   ],
   "outputs": [],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T11:33:26.980741Z",
     "start_time": "2024-08-10T11:32:34.155304Z"
    }
   },
   "source": [
    "train(model, train_loader, epochs=15)\n",
    "\n",
    "user_id = 0\n",
    "top_movies_df = model.predict_all_movies(user_id, num_top_movies=5)\n",
    "\n",
    "print(top_movies_df)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.4477880144454849\n",
      "Epoch 2, Loss: 0.8809124449469383\n",
      "Epoch 3, Loss: 0.8369741505029792\n",
      "Epoch 4, Loss: 0.8192572370981911\n",
      "Epoch 5, Loss: 0.8079927985819196\n",
      "Epoch 6, Loss: 0.7996937072742313\n",
      "Epoch 7, Loss: 0.7927433150896108\n",
      "Epoch 8, Loss: 0.7859973247357842\n",
      "Epoch 9, Loss: 0.7799501406101561\n",
      "Epoch 10, Loss: 0.7740134602926209\n",
      "Epoch 11, Loss: 0.7681666163397537\n",
      "Epoch 12, Loss: 0.7624148112112181\n",
      "Epoch 13, Loss: 0.7569196915977365\n",
      "Epoch 14, Loss: 0.750835423811231\n",
      "Epoch 15, Loss: 0.7450900434379919\n",
      "   MovieID  PredictedRating\n",
      "0     3308         5.192263\n",
      "1     2309         5.122907\n",
      "2      208         5.114661\n",
      "3      713         5.093707\n",
      "4     1041         5.076642\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation using already defined metrics + MAP + NDCG#"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T11:33:27.735488Z",
     "start_time": "2024-08-10T11:33:26.981622Z"
    }
   },
   "source": [
    "test_dataset = MovieLensDataset(test_df)\n",
    "test_loader = DataLoader(test_dataset, batch_size=512, shuffle=True)\n",
    "\n",
    "test_metrics = model.evaluate(test_loader)\n",
    "print(test_metrics)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mae': 0.725, 'rmse': 0.919, 'precision': 0.838, 'recall': 0.428, 'f1': 0.566, 'roc_auc': 0.658, 'map': 0.5743128092004386, 'ndcg': 0.9816392953753538}\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
